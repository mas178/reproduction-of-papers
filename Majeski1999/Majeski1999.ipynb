{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6f08d4-03ea-42d9-b68f-18f01ca4a143",
   "metadata": {},
   "source": [
    "# Agent mobility and the evolution of cooperative communities\n",
    "\n",
    "Majeski, S. J., Linden, G., Linden, C., & Spitzer, A. (1999). Agent mobility and the evolution of cooperative communities. Complexity, 5(1), 16-24.\n",
    "\n",
    "## Abstract\n",
    "\n",
    "An  artificial  world  is  constructed  that  is  based  upon  a  spatial  iterated prisoner’s  dilemma  game.  Several  additional  features  are  introduced  into this  model,  the  key  feature  being  the  ability  of  agents  to  move  around  in their  world.  Movement  is  a  mechanism  for  exit  or  noncompulsory  play. When  agents  can  move,  high  levels  of  cooperation  are  achieved  more frequently  and  are  considerably  more  stable  than  when  they  cannot move.  Also,  when  cooperative  worlds  occur,  they  are  generated  and sustained  by  the  formation  of  networks  of  densely  connected “cooperative”  agents  that  can  withstand  invasion  and  parasitism  by noncooperative  agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e160823a-bc49-46d8-bd79-9c0b6eec08e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia: 1.10.2\n"
     ]
    }
   ],
   "source": [
    "println(\"Julia: $(VERSION)\")\n",
    "using Agents\n",
    "using Random: shuffle!\n",
    "using Statistics: mean\n",
    "using Test: @testset, @test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a59701-40df-4cff-a829-abb8eab4be52",
   "metadata": {},
   "source": [
    "## 1. Define the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a0ee0c-dfde-4b3c-bcd4-e9dc0e11ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:         | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Agent and agent_color | \u001b[32m   5  \u001b[39m\u001b[36m    5  \u001b[39m\u001b[0m0.1s\n"
     ]
    }
   ],
   "source": [
    "@enum Strategy C D\n",
    "\n",
    "mutable struct Agent <: AbstractAgent\n",
    "    id::Int\n",
    "    pos::Dims{2}\n",
    "    strategy::Strategy\n",
    "    payoff::Float64\n",
    "    \n",
    "    Agent(id, pos, strategy) = new(id, pos, strategy, 0.0)\n",
    "    Agent(id, pos) = Agent(id, pos, D)\n",
    "    Agent() = Agent(1, (1, 1))\n",
    "end\n",
    "\n",
    "function agent_color(agent::Agent)\n",
    "    if agent.strategy == C\n",
    "        :blue\n",
    "    elseif agent.strategy == D\n",
    "        :red\n",
    "    else\n",
    "        error(\"Something wrong...\")\n",
    "    end\n",
    "end\n",
    "\n",
    "@testset \"Agent and agent_color\" begin\n",
    "    agent = Agent()\n",
    "    @test agent.id == 1\n",
    "    @test agent.pos == (1, 1)\n",
    "    @test agent.strategy == D\n",
    "    @test agent.payoff == 0.0\n",
    "    agent_color(agent) == :red\n",
    "    \n",
    "    agent.strategy = C\n",
    "    agent_color(agent) == :blue\n",
    "    \n",
    "    agent.payoff = 9.9\n",
    "    @test agent.payoff == 9.9\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a07857-c957-4816-9431-f92c8dd3ccb2",
   "metadata": {},
   "source": [
    "## 2. Define the prisoner's dilemma game (PD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f482cc77-0e56-49e1-ac1f-72f73266d9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "play PD       | \u001b[32m   4  \u001b[39m\u001b[36m    4  \u001b[39m\u001b[0m0.0s\n"
     ]
    }
   ],
   "source": [
    "# Payoff Table\n",
    "const PAYOFFS = (\n",
    "    R = 1.0,   # CC\n",
    "    T = 3.0,   # DC\n",
    "    S = -3.0,  # CD\n",
    "    P = -1.0   # DD\n",
    ")\n",
    "\n",
    "# Prisoner's Dilemma (PD)\n",
    "function play(focal::Agent, opponent::Agent, payoffs::NamedTuple = PAYOFFS)::Tuple{Float64, Float64}\n",
    "    s_pair = focal.strategy, opponent.strategy\n",
    "    \n",
    "    return if s_pair == (C, C)\n",
    "        payoffs.R, payoffs.R\n",
    "    elseif s_pair == (D, C)\n",
    "        payoffs.T, payoffs.S\n",
    "    elseif s_pair == (C, D)\n",
    "        payoffs.S, payoffs.T\n",
    "    elseif s_pair == (D, D)\n",
    "        payoffs.P, payoffs.P\n",
    "    else\n",
    "        error(\"Something wrong...\")\n",
    "    end\n",
    "end\n",
    "\n",
    "@testset \"play PD\" begin\n",
    "    agent1 = Agent()\n",
    "    agent2 = Agent()\n",
    "\n",
    "    agent1.strategy, agent2.strategy = (C, C)\n",
    "    @test play(agent1, agent2) == (1.0, 1.0)\n",
    "\n",
    "    agent1.strategy, agent2.strategy = (D, C)\n",
    "    @test play(agent1, agent2) == (3.0, -3.0)\n",
    "\n",
    "    agent1.strategy, agent2.strategy = (C, D)\n",
    "    @test play(agent1, agent2) == (-3.0, 3.0)\n",
    "\n",
    "    agent1.strategy, agent2.strategy = (D, D)\n",
    "    @test play(agent1, agent2) == (-1.0, -1.0)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0983efa4-9049-4024-82b7-7fe69f73d62e",
   "metadata": {},
   "source": [
    "## 3. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13147483-3207-45ae-8a4d-2369b2b7c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "□■□■□□□■□□□■□□□■■□■□\n",
      "□□□□□□□■□□□□□□□■□□□□\n",
      "□□□□□□■□□□□□□□□□□□□□\n",
      "■□□□□□□□■□□□■■□■□■□□\n",
      "□□□□□□■□□□□■□□□□□■□□\n",
      "□□□□□□□□□□■□□□□□□□□■\n",
      "□□□□□□□□□□□□□□■□□□□□\n",
      "□□■□□□■□■□□□□□□□□■□□\n",
      "□□□□■■□□■□□□□□■□□□□□\n",
      "□■□□□□□□■□□□■□□□□□□□\n",
      "□□■□□□□□□□■□□□■□□□□□\n",
      "□□□□□□■□□□□□□□□■□□□□\n",
      "□□□■□□□□□□□□□□□□□□□□\n",
      "□□□□□□□□□■□□□□□□□□□□\n",
      "□■□□■□□□■□■□■□□□□□■■\n",
      "□□□■□■□■□■■□□□□□□□□□\n",
      "□□□□□□■□□□□■□□□■□□□□\n",
      "□□□□□□□□□□□□□□□□□□□□\n",
      "□□□□□□□□□□□□□□□□■□□□\n",
      "□□□■□□■■□□□□□□□□■□□□\n",
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Model         | \u001b[32m   2  \u001b[39m\u001b[36m    2  \u001b[39m\u001b[0m0.1s\n"
     ]
    }
   ],
   "source": [
    "function build_model(; dims = (20, 20), properties)::ABM\n",
    "    space = GridSpace(dims; periodic = true, metric = :chebyshev)\n",
    "    model = ABM(Agent, space; properties)\n",
    "\n",
    "    space_n = dims[1] * dims[2]\n",
    "    is_agent_vec = shuffle!(vcat(fill(true, properties[:N]), fill(false, space_n - properties[:N])))\n",
    "    agent_strategy_vec = shuffle!(vcat(fill(C, Int(properties[:N] / 2)), fill(D, Int(properties[:N] / 2))))\n",
    "    \n",
    "    space_id = 1\n",
    "    agent_id = 1\n",
    "    \n",
    "    for x in 1:dims[1]\n",
    "        for y in 1:dims[2]\n",
    "            if is_agent_vec[space_id]\n",
    "                add_agent_pos!(Agent(agent_id, (x, y), agent_strategy_vec[agent_id]), model)\n",
    "                agent_id += 1\n",
    "            end\n",
    "            space_id += 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return model\n",
    "end\n",
    "\n",
    "c_rate(model::ABM)::Float64 = mean([agent.strategy == C for agent in allagents(model)])\n",
    "\n",
    "@testset \"Model\" begin\n",
    "    model = build_model(properties = Dict(:N => 60))\n",
    "\n",
    "    @test nagents(model) == 60\n",
    "    @test c_rate(model) == 0.5\n",
    "\n",
    "    pos_vec = [agent.pos for agent in allagents(model)]\n",
    "    for x in 1:20\n",
    "        for y in 1:20\n",
    "            if (x, y) ∈ pos_vec\n",
    "                print(\"■\")\n",
    "            else\n",
    "                print(\"□\")\n",
    "            end\n",
    "        end\n",
    "        print(\"\\n\")\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa061280-f93b-4e4b-a0f7-87e3b893ea6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardABM with 60 agents of type Agent\n",
       " agents container: Dict\n",
       " space: GridSpace with size (20, 20), metric=chebyshev, periodic=true\n",
       " scheduler: fastest\n",
       " properties: N"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function model_step!(model)\n",
    "    agents_done = []\n",
    "\n",
    "    for focal_agent in allagents(model)\n",
    "        opponent_agent = random_nearby_agent(focal_agent, model)\n",
    "        focal_payoff, opponent_payoff = play(focal_agent, opponent_agent)\n",
    "        focal_agent.payoff += focal_payoff\n",
    "        opponent_agent.payoff += opponent_payoff\n",
    "\n",
    "        push!(agents_done, focal_agent.id)\n",
    "        push!(agents_done, opponent_agent.id)\n",
    "\n",
    "        # ToDo: すでにゲーム済みのエージェントが二回目のゲームをプレイしないようにする\n",
    "    end\n",
    "\n",
    "    # At the start of the next generation, each lattice-site is occupied by the player with the highest score among the previous owner and the immediate neighbours.\n",
    "    for agent in allagents(model)\n",
    "        best_payoff = agent.payoff\n",
    "        agent.next_strategy = agent.strategy\n",
    "\n",
    "        for neighbor in nearby_agents(agent, model)\n",
    "            if neighbor.payoff > best_payoff\n",
    "                best_payoff = neighbor.payoff\n",
    "                agent.next_strategy = neighbor.strategy\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # update strategy\n",
    "    for agent in allagents(model)\n",
    "        agent.prev_strategy = agent.strategy\n",
    "        agent.strategy = agent.next_strategy\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728971a4-1512-44b1-a61c-887868a5c184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
